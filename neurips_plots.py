


import matplotlib.pyplot as plt
base_dir = './neurips_paper/'


'''
Exp details : [CIFAR-10] varying Ps and Thetas 

    n_runs = 100 
    Thetas = list( np.arange( 0.001, 0.05, 0.005 ) )
    Ps = list(np.arange(0.015, 0.3, 0.015)) 
    T = 500 
    thresholds = np.linspace(0.2,0.95,20)
'''
label = 'cifar10-varying-Ps-Thetas-exp' 
mistake_levels = list(range(0, 50))
abstention_levels = [ -1.        ,  -1.        , 140.5       , 140.8       ,
       136.92307692, 137.56521739, 134.37142857, 132.10416667,
       131.        , 126.85897436, 124.16666667, 119.08602151,
       114.36458333, 110.89795918, 106.53535354, 101.        ,
        97.67      ,  92.93      ,  88.56      ,  85.46      ,
        80.96      ,  78.1       ,  74.37      ,  71.53      ,
        67.89      ,  64.52      ,  61.81      ,  58.79      ,
        56.38      ,  53.3       ,  50.71      ,  48.09      ,
        46.06      ,  43.38      ,  40.91      ,  38.56      ,
        36.61      ,  34.51      ,  32.52      ,  30.59      ,
        28.58      ,  26.79      ,  24.76      ,  23.16      ,
        21.22      ,  19.73      ,  18.19      ,  16.49      ,
        15.05      ,  13.37      ]
mistake_levels = mistake_levels[2:]
abstention_levels = abstention_levels[2:] 

raw_abs =  [54.93, 53.2, 59.61, 57.7, 55.33, 57.5, 54.75, 46.34, 45.95, 45.51, 66.34, 69.7, 66.52, 69.43, 51.69, 51.28, 49.82, 50.63, 54.76, 50.19, 82.59, 78.12121212121212, 78.11458333333333, 63.94, 59.85, 62.59, 63.31, 51.41, 48.44, 51.82, 90.34020618556701, 93.70408163265306, 69.85, 71.47, 75.28, 60.84, 59.51, 58.91, 59.8, 53.0, 108.6413043478261, 109.73195876288659, 85.07, 87.86, 72.91, 69.21, 67.9, 69.53, 59.75, 60.39, 118.45744680851064, 95.59, 96.29, 99.11, 84.4, 80.77, 68.47, 72.36, 71.07, 66.43, 125.44680851063829, 108.23, 104.67, 88.97, 92.33, 85.3, 81.68, 82.26, 75.48, 73.27, 137.17777777777778, 115.35, 114.88, 103.86, 99.48, 92.41, 96.89, 86.59, 83.06, 81.32, 138.8780487804878, 124.84693877551021, 123.11111111111111, 111.92, 103.94, 101.47, 93.33, 93.52, 86.51, 89.26, 148.12345679012347, 125.38383838383838, 119.99, 122.44, 109.27, 110.09, 102.0, 97.5, 95.57, 92.98, 155.27027027027026, 142.7171717171717, 128.56, 126.67, 119.87, 114.83, 110.41, 106.06, 104.83, 102.12, 163.42857142857142, 149.13, 139.23, 128.34, 131.37, 121.96, 116.53, 118.88, 108.81, 104.22, 177.5, 161.1875, 147.37, 139.51, 128.43, 129.8, 125.83, 120.36, 122.24, 114.03, 175.88888888888889, 168.59183673469389, 149.12, 147.25, 138.86, 134.42, 133.25, 128.46, 123.42, 125.15, 188.22, 175.80434782608697, 164.08, 154.47, 146.14, 140.38, 136.59, 135.83, 132.35, 127.59, 198.26, 183.25, 168.45, 160.75, 156.09, 149.92, 141.8, 143.57, 137.88, 135.15, 197.95833333333334, 177.65, 168.05, 164.3, 166.36, 162.84, 154.54, 148.51, 146.05, 143.96, 205.4878048780488, 187.46, 177.27, 171.74, 168.17, 164.87, 157.79, 158.81, 155.57, 152.51, 217.40540540540542, 190.3838383838384, 186.27, 181.16, 174.76, 167.52, 166.32, 162.84, 158.4, 157.8]

raw_mis =  [41.5, 41.55, 38.57, 39.41, 41.55, 40.09, 41.48, 46.13, 46.41, 46.83, 37.91, 35.39, 37.34, 36.29, 45.65, 45.41, 46.21, 46.03, 43.9, 46.17, 32.32, 34.75757575757576, 34.59375, 42.44, 44.81, 42.46, 42.2, 49.41, 51.21, 49.16, 31.144329896907216, 29.79591836734694, 40.99, 40.59, 38.13, 46.61, 47.49, 47.3, 47.31, 51.16, 25.195652173913043, 24.144329896907216, 35.58, 34.63, 42.39, 44.2, 44.8, 44.76, 49.78, 49.62, 23.840425531914892, 33.17, 33.71, 31.32, 38.52, 40.38, 47.97, 45.4, 45.88, 49.69, 22.06382978723404, 30.34, 32.29, 39.17, 37.68, 42.12, 43.01, 43.77, 46.59, 48.37, 19.633333333333333, 28.73, 29.36, 34.69, 35.88, 40.25, 39.19, 45.06, 46.5, 47.92, 20.829268292682926, 26.846938775510203, 27.12121212121212, 33.08, 37.55, 38.47, 43.59, 43.71, 48.07, 46.09, 18.382716049382715, 28.08080808080808, 30.92, 30.45, 37.57, 37.59, 41.85, 43.35, 45.63, 47.02, 18.72972972972973, 23.818181818181817, 30.78, 30.18, 34.66, 38.44, 40.11, 42.35, 42.85, 45.52, 17.142857142857142, 23.12, 28.43, 33.26, 32.19, 36.15, 40.23, 38.7, 44.98, 46.84, 14.558823529411764, 20.5, 26.28, 30.65, 35.63, 36.0, 37.72, 40.65, 40.46, 43.72, 16.142857142857142, 19.612244897959183, 27.31, 29.25, 33.98, 36.38, 36.15, 39.53, 42.51, 41.27, 14.32, 19.434782608695652, 24.28, 28.04, 33.18, 35.34, 38.52, 37.75, 40.82, 43.13, 13.34, 18.119565217391305, 23.4, 28.47, 30.09, 33.62, 37.09, 37.17, 39.9, 41.73, 14.458333333333334, 22.43, 26.9, 29.09, 27.71, 30.43, 33.62, 37.21, 38.97, 40.56, 14.317073170731707, 20.71, 25.42, 28.23, 31.2, 31.45, 34.81, 35.39, 36.83, 39.63, 10.91891891891892, 20.484848484848484, 23.35, 27.11, 29.33, 32.57, 33.3, 35.64, 37.18, 39.39]


fig = plt.figure()
plt.plot(raw_abs, raw_mis, 'o', color='red', label='raw abs vs raw mistakes')
plt.plot(abstention_levels, mistake_levels, '^', color='black', label='offline experts')
plt.legend(loc='lower right')
plt.savefig( base_dir + label + '-comparative_raw_a_vs_m_linear_discrete.png' )

